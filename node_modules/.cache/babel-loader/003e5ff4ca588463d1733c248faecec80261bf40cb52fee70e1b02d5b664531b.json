{"ast":null,"code":"var _jsxFileName = \"/Users/yashagrawal/Documents/Northwestern/Fall2023/CS338/InterviewPrep/src/components/VoiceToText.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from 'react';\nimport './VoiceToText.css';\n\n// FOR NOW - TRANSCRIPT IS THE GPT RESPONSE INTO AUDIO, USERSPEECH IS THE SPEECH FROM USER GOING INTO GPT\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst VoiceToText = ({\n  transcript,\n  setTranscript,\n  setUserSpeech\n}) => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [audioFile, setAudioFile] = useState(null);\n  const [isButtonDisabled, setIsButtonDisabled] = useState(false);\n  useEffect(() => {\n    if (transcript) {\n      // Automatically click the button when transcript is not empty\n      handleGenerateAudio();\n    }\n  }, [transcript]);\n  useEffect(() => {\n    if (isButtonDisabled) {\n      const timeout = setTimeout(() => {\n        setIsButtonDisabled(false);\n      }, 2000);\n      return () => clearTimeout(timeout);\n    }\n  }, [isButtonDisabled]);\n  const recognitionRef = useRef(null); // Using useRef for recognition\n\n  const handleStop = () => {\n    setIsListening(false);\n    setIsButtonDisabled(true);\n    if (recognitionRef.current) {\n      recognitionRef.current.onresult = null; // Ensure no more results are processed\n      recognitionRef.current.stop();\n    }\n  };\n  const handleStart = () => {\n    if (isListening === false) {\n      if (window.SpeechRecognition || window.webkitSpeechRecognition) {\n        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n        if (!recognitionRef.current) {\n          recognitionRef.current = new SpeechRecognition();\n          recognitionRef.current.continuous = true;\n          recognitionRef.current.interimResults = true;\n        }\n        setIsListening(true);\n        recognitionRef.current.onstart = () => setIsListening(true);\n        recognitionRef.current.onresult = event => {\n          let finalSpeech = '';\n          for (let i = 0; i < event.results.length; i++) {\n            if (event.results[i].isFinal) {\n              finalSpeech += event.results[i][0].transcript;\n            }\n          }\n          if (finalSpeech !== '') {\n            console.log('finalspeech in voicetotext: ' + finalSpeech);\n            setUserSpeech(finalSpeech); // puts non-null user speech into the userSpeech variable accessible to gpt\n          }\n        };\n\n        recognitionRef.current.onerror = event => {\n          console.error(\"Error occurred in recognition:\", event.error);\n        };\n        recognitionRef.current.start();\n      } else {\n        alert(\"Your browser does not support the Web Speech API. Please try a different browser.\");\n      }\n    }\n  };\n  const handleGenerateAudio = async () => {\n    sendTranscriptToBackend(transcript);\n  };\n\n  // const sendTranscriptToBackend = async (text) => {\n  //     const backendUrl = 'http://127.0.0.1:5001/generate_audio';\n\n  //     try {\n  //         const response = await fetch(backendUrl, {\n  //             method: 'POST',\n  //             headers: {\n  //                 'Content-Type': 'application/json'\n  //             },\n  //             body: JSON.stringify({ text: text })\n  //         });\n\n  //         if (!response.ok) {\n  //             throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n  //         }\n\n  //         const responseData = await response.json();\n  //         setAudioFile(responseData.audio_file);\n\n  //     } catch (error) {\n  //         console.error('Error sending transcript to backend:', error);\n  //     }\n  // };\n\n  const sendTranscriptToBackend = async text => {\n    const apiUrl = \"https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM\";\n    const payload = {\n      \"text\": text,\n      \"model_id\": \"eleven_monolingual_v1\",\n      \"voice_settings\": {\n        \"stability\": 0,\n        \"similarity_boost\": 0,\n        \"style\": 0,\n        \"use_speaker_boost\": true\n      }\n    };\n    const headers = {\n      \"Content-Type\": \"application/json\",\n      \"xi-api-key\": \"321547ec48256661cb0b640353bde72c\"\n    };\n    try {\n      const response = await fetch(apiUrl, {\n        method: 'POST',\n        headers: headers,\n        body: JSON.stringify(payload)\n      });\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n      }\n      const audioBlob = await response.blob();\n      const audioUrl = URL.createObjectURL(audioBlob);\n      setAudioFile(audioUrl);\n      console.log('Response:', response);\n      console.log('Audio Blob:', audioBlob);\n      console.log('Audio URL:', audioUrl);\n    } catch (error) {\n      console.error('Error sending transcript to Eleven Labs:', error);\n    }\n    handleStop();\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      id: \"generate-audio-button\",\n      className: `voice-to-text-button ${isButtonDisabled ? 'disabled' : ''}`,\n      onClick: isListening ? handleStop : handleStart,\n      disabled: isButtonDisabled,\n      children: isListening ? 'Stop Listening' : 'Start Listening'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 150,\n      columnNumber: 13\n    }, this), audioFile && /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Your Generated Audio File:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 159,\n        columnNumber: 21\n      }, this), /*#__PURE__*/_jsxDEV(\"audio\", {\n        controls: true,\n        src: audioFile,\n        children: \"Your browser does not support the audio tag.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 160,\n        columnNumber: 21\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 158,\n      columnNumber: 17\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 149,\n    columnNumber: 9\n  }, this);\n};\n_s(VoiceToText, \"/0g2haZnScISZ6Hl9sd46YaNmn8=\");\n_c = VoiceToText;\nexport default VoiceToText;\nvar _c;\n$RefreshReg$(_c, \"VoiceToText\");","map":{"version":3,"names":["React","useState","useRef","useEffect","jsxDEV","_jsxDEV","VoiceToText","transcript","setTranscript","setUserSpeech","_s","isListening","setIsListening","audioFile","setAudioFile","isButtonDisabled","setIsButtonDisabled","handleGenerateAudio","timeout","setTimeout","clearTimeout","recognitionRef","handleStop","current","onresult","stop","handleStart","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","onstart","event","finalSpeech","i","results","length","isFinal","console","log","onerror","error","start","alert","sendTranscriptToBackend","text","apiUrl","payload","headers","response","fetch","method","body","JSON","stringify","ok","Error","status","statusText","audioBlob","blob","audioUrl","URL","createObjectURL","children","id","className","onClick","disabled","fileName","_jsxFileName","lineNumber","columnNumber","controls","src","_c","$RefreshReg$"],"sources":["/Users/yashagrawal/Documents/Northwestern/Fall2023/CS338/InterviewPrep/src/components/VoiceToText.jsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from 'react';\nimport './VoiceToText.css';\n\n// FOR NOW - TRANSCRIPT IS THE GPT RESPONSE INTO AUDIO, USERSPEECH IS THE SPEECH FROM USER GOING INTO GPT\n\nconst VoiceToText = ({ transcript, setTranscript, setUserSpeech }) => {\n    const [isListening, setIsListening] = useState(false);\n    const [audioFile, setAudioFile] = useState(null);\n    const [isButtonDisabled, setIsButtonDisabled] = useState(false);\n\n    useEffect(() => {\n        if (transcript) {\n          // Automatically click the button when transcript is not empty\n          handleGenerateAudio();\n        }\n    }, [transcript]);\n\n    useEffect(() => {\n    if (isButtonDisabled) {\n      const timeout = setTimeout(() => {\n        setIsButtonDisabled(false);\n      }, 2000);\n\n      return () => clearTimeout(timeout);\n    }\n  }, [isButtonDisabled]);\n\n    const recognitionRef = useRef(null);  // Using useRef for recognition\n\n    const handleStop = () => {\n        setIsListening(false);\n        setIsButtonDisabled(true);\n        if (recognitionRef.current) {\n            recognitionRef.current.onresult = null;  // Ensure no more results are processed\n            recognitionRef.current.stop();\n        }\n    };\n\n    const handleStart = () => {\n        if(isListening === false){\n            if (window.SpeechRecognition || window.webkitSpeechRecognition) {\n                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n                if (!recognitionRef.current) {\n                    recognitionRef.current = new SpeechRecognition();\n                    recognitionRef.current.continuous = true;\n                    recognitionRef.current.interimResults = true;\n                }\n\n                setIsListening(true);\n                recognitionRef.current.onstart = () => setIsListening(true);\n\n                recognitionRef.current.onresult = (event) => {\n                    let finalSpeech = '';\n                    for (let i = 0; i < event.results.length; i++) {\n                        if (event.results[i].isFinal) {\n                            finalSpeech += event.results[i][0].transcript;\n                        }\n                    }\n                    if(finalSpeech !== '') {\n                        console.log('finalspeech in voicetotext: ' + finalSpeech);\n                        setUserSpeech(finalSpeech); // puts non-null user speech into the userSpeech variable accessible to gpt\n                    }\n                };\n\n                recognitionRef.current.onerror = (event) => {\n                    console.error(\"Error occurred in recognition:\", event.error);\n                };\n\n                recognitionRef.current.start();\n            } else {\n                alert(\"Your browser does not support the Web Speech API. Please try a different browser.\");\n            }\n        }\n    };\n    \n\n    const handleGenerateAudio = async () => {\n        sendTranscriptToBackend(transcript);\n    };\n\n    // const sendTranscriptToBackend = async (text) => {\n    //     const backendUrl = 'http://127.0.0.1:5001/generate_audio';\n\n    //     try {\n    //         const response = await fetch(backendUrl, {\n    //             method: 'POST',\n    //             headers: {\n    //                 'Content-Type': 'application/json'\n    //             },\n    //             body: JSON.stringify({ text: text })\n    //         });\n\n    //         if (!response.ok) {\n    //             throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n    //         }\n\n    //         const responseData = await response.json();\n    //         setAudioFile(responseData.audio_file);\n\n    //     } catch (error) {\n    //         console.error('Error sending transcript to backend:', error);\n    //     }\n    // };\n    \n    const sendTranscriptToBackend = async (text) => {\n        const apiUrl = \"https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM\";\n        const payload = {\n            \"text\": text,\n            \"model_id\": \"eleven_monolingual_v1\",\n            \"voice_settings\": {\n                \"stability\": 0,\n                \"similarity_boost\": 0,\n                \"style\": 0,\n                \"use_speaker_boost\": true\n            }\n        };\n\n        const headers = {\n            \"Content-Type\": \"application/json\",\n            \"xi-api-key\": \"321547ec48256661cb0b640353bde72c\"\n        };\n\n        try {\n            const response = await fetch(apiUrl, {\n                method: 'POST',\n                headers: headers,\n                body: JSON.stringify(payload)\n            });\n\n            if (!response.ok) {\n                throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n            }\n\n            const audioBlob = await response.blob();\n            const audioUrl = URL.createObjectURL(audioBlob);\n            setAudioFile(audioUrl);\n            console.log('Response:', response);\n            console.log('Audio Blob:', audioBlob);\n            console.log('Audio URL:', audioUrl);\n\n        } catch (error) {\n            console.error('Error sending transcript to Eleven Labs:', error);\n        }\n\n        handleStop();\n    };\n\n    return (\n        <div>\n            <button id=\"generate-audio-button\"\n                className={`voice-to-text-button ${isButtonDisabled ? 'disabled' : ''}`}\n                onClick={isListening ? handleStop : handleStart}\n                disabled={isButtonDisabled}>\n                {isListening ? 'Stop Listening' : 'Start Listening'}\n            </button>\n    \n            {audioFile && (\n                <div>\n                    <h3>Your Generated Audio File:</h3>\n                    <audio controls src={audioFile}>\n                        Your browser does not support the audio tag.\n                    </audio>\n                </div>\n            )}\n        </div>\n    );\n    \n};\n\nexport default VoiceToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAC1D,OAAO,mBAAmB;;AAE1B;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAEA,MAAMC,WAAW,GAAGA,CAAC;EAAEC,UAAU;EAAEC,aAAa;EAAEC;AAAc,CAAC,KAAK;EAAAC,EAAA;EAClE,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,SAAS,EAAEC,YAAY,CAAC,GAAGb,QAAQ,CAAC,IAAI,CAAC;EAChD,MAAM,CAACc,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EAE/DE,SAAS,CAAC,MAAM;IACZ,IAAII,UAAU,EAAE;MACd;MACAU,mBAAmB,CAAC,CAAC;IACvB;EACJ,CAAC,EAAE,CAACV,UAAU,CAAC,CAAC;EAEhBJ,SAAS,CAAC,MAAM;IAChB,IAAIY,gBAAgB,EAAE;MACpB,MAAMG,OAAO,GAAGC,UAAU,CAAC,MAAM;QAC/BH,mBAAmB,CAAC,KAAK,CAAC;MAC5B,CAAC,EAAE,IAAI,CAAC;MAER,OAAO,MAAMI,YAAY,CAACF,OAAO,CAAC;IACpC;EACF,CAAC,EAAE,CAACH,gBAAgB,CAAC,CAAC;EAEpB,MAAMM,cAAc,GAAGnB,MAAM,CAAC,IAAI,CAAC,CAAC,CAAE;;EAEtC,MAAMoB,UAAU,GAAGA,CAAA,KAAM;IACrBV,cAAc,CAAC,KAAK,CAAC;IACrBI,mBAAmB,CAAC,IAAI,CAAC;IACzB,IAAIK,cAAc,CAACE,OAAO,EAAE;MACxBF,cAAc,CAACE,OAAO,CAACC,QAAQ,GAAG,IAAI,CAAC,CAAE;MACzCH,cAAc,CAACE,OAAO,CAACE,IAAI,CAAC,CAAC;IACjC;EACJ,CAAC;EAED,MAAMC,WAAW,GAAGA,CAAA,KAAM;IACtB,IAAGf,WAAW,KAAK,KAAK,EAAC;MACrB,IAAIgB,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE;QAC5D,MAAMD,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;QACpF,IAAI,CAACR,cAAc,CAACE,OAAO,EAAE;UACzBF,cAAc,CAACE,OAAO,GAAG,IAAIK,iBAAiB,CAAC,CAAC;UAChDP,cAAc,CAACE,OAAO,CAACO,UAAU,GAAG,IAAI;UACxCT,cAAc,CAACE,OAAO,CAACQ,cAAc,GAAG,IAAI;QAChD;QAEAnB,cAAc,CAAC,IAAI,CAAC;QACpBS,cAAc,CAACE,OAAO,CAACS,OAAO,GAAG,MAAMpB,cAAc,CAAC,IAAI,CAAC;QAE3DS,cAAc,CAACE,OAAO,CAACC,QAAQ,GAAIS,KAAK,IAAK;UACzC,IAAIC,WAAW,GAAG,EAAE;UACpB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACG,OAAO,CAACC,MAAM,EAAEF,CAAC,EAAE,EAAE;YAC3C,IAAIF,KAAK,CAACG,OAAO,CAACD,CAAC,CAAC,CAACG,OAAO,EAAE;cAC1BJ,WAAW,IAAID,KAAK,CAACG,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC5B,UAAU;YACjD;UACJ;UACA,IAAG2B,WAAW,KAAK,EAAE,EAAE;YACnBK,OAAO,CAACC,GAAG,CAAC,8BAA8B,GAAGN,WAAW,CAAC;YACzDzB,aAAa,CAACyB,WAAW,CAAC,CAAC,CAAC;UAChC;QACJ,CAAC;;QAEDb,cAAc,CAACE,OAAO,CAACkB,OAAO,GAAIR,KAAK,IAAK;UACxCM,OAAO,CAACG,KAAK,CAAC,gCAAgC,EAAET,KAAK,CAACS,KAAK,CAAC;QAChE,CAAC;QAEDrB,cAAc,CAACE,OAAO,CAACoB,KAAK,CAAC,CAAC;MAClC,CAAC,MAAM;QACHC,KAAK,CAAC,mFAAmF,CAAC;MAC9F;IACJ;EACJ,CAAC;EAGD,MAAM3B,mBAAmB,GAAG,MAAAA,CAAA,KAAY;IACpC4B,uBAAuB,CAACtC,UAAU,CAAC;EACvC,CAAC;;EAED;EACA;;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA;EACA;EACA;;EAEA;EACA;;EAEA;EACA;EACA;EACA;;EAEA,MAAMsC,uBAAuB,GAAG,MAAOC,IAAI,IAAK;IAC5C,MAAMC,MAAM,GAAG,kEAAkE;IACjF,MAAMC,OAAO,GAAG;MACZ,MAAM,EAAEF,IAAI;MACZ,UAAU,EAAE,uBAAuB;MACnC,gBAAgB,EAAE;QACd,WAAW,EAAE,CAAC;QACd,kBAAkB,EAAE,CAAC;QACrB,OAAO,EAAE,CAAC;QACV,mBAAmB,EAAE;MACzB;IACJ,CAAC;IAED,MAAMG,OAAO,GAAG;MACZ,cAAc,EAAE,kBAAkB;MAClC,YAAY,EAAE;IAClB,CAAC;IAED,IAAI;MACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAACJ,MAAM,EAAE;QACjCK,MAAM,EAAE,MAAM;QACdH,OAAO,EAAEA,OAAO;QAChBI,IAAI,EAAEC,IAAI,CAACC,SAAS,CAACP,OAAO;MAChC,CAAC,CAAC;MAEF,IAAI,CAACE,QAAQ,CAACM,EAAE,EAAE;QACd,MAAM,IAAIC,KAAK,CAAE,uBAAsBP,QAAQ,CAACQ,MAAO,IAAGR,QAAQ,CAACS,UAAW,EAAC,CAAC;MACpF;MAEA,MAAMC,SAAS,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;MACvC,MAAMC,QAAQ,GAAGC,GAAG,CAACC,eAAe,CAACJ,SAAS,CAAC;MAC/C9C,YAAY,CAACgD,QAAQ,CAAC;MACtBvB,OAAO,CAACC,GAAG,CAAC,WAAW,EAAEU,QAAQ,CAAC;MAClCX,OAAO,CAACC,GAAG,CAAC,aAAa,EAAEoB,SAAS,CAAC;MACrCrB,OAAO,CAACC,GAAG,CAAC,YAAY,EAAEsB,QAAQ,CAAC;IAEvC,CAAC,CAAC,OAAOpB,KAAK,EAAE;MACZH,OAAO,CAACG,KAAK,CAAC,0CAA0C,EAAEA,KAAK,CAAC;IACpE;IAEApB,UAAU,CAAC,CAAC;EAChB,CAAC;EAED,oBACIjB,OAAA;IAAA4D,QAAA,gBACI5D,OAAA;MAAQ6D,EAAE,EAAC,uBAAuB;MAC9BC,SAAS,EAAG,wBAAuBpD,gBAAgB,GAAG,UAAU,GAAG,EAAG,EAAE;MACxEqD,OAAO,EAAEzD,WAAW,GAAGW,UAAU,GAAGI,WAAY;MAChD2C,QAAQ,EAAEtD,gBAAiB;MAAAkD,QAAA,EAC1BtD,WAAW,GAAG,gBAAgB,GAAG;IAAiB;MAAA2D,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/C,CAAC,EAER5D,SAAS,iBACNR,OAAA;MAAA4D,QAAA,gBACI5D,OAAA;QAAA4D,QAAA,EAAI;MAA0B;QAAAK,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACnCpE,OAAA;QAAOqE,QAAQ;QAACC,GAAG,EAAE9D,SAAU;QAAAoD,QAAA,EAAC;MAEhC;QAAAK,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAO,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACP,CACR;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACA,CAAC;AAGd,CAAC;AAAC/D,EAAA,CAlKIJ,WAAW;AAAAsE,EAAA,GAAXtE,WAAW;AAoKjB,eAAeA,WAAW;AAAC,IAAAsE,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}