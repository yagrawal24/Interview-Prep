{"ast":null,"code":"var _jsxFileName = \"/Users/yashagrawal/Documents/Northwestern/Fall2023/CS338/InterviewPrep/src/components/VoiceToText.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from 'react';\n\n// FOR NOW - TRANSCRIPT IS THE GPT RESPONSE INTO AUDIO, USERSPEECH IS THE SPEECH FROM USER GOING INTO GPT\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst VoiceToText = ({\n  transcript,\n  setTranscript,\n  setUserSpeech\n}) => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [audioFile, setAudioFile] = useState(null);\n  useEffect(() => {\n    if (transcript) {\n      // Automatically click the button when transcript is not empty\n      handleGenerateAudio();\n    }\n  }, [transcript]);\n  const handleTranscriptChange = e => {\n    setTranscript(e.target.value);\n  };\n  const recognitionRef = useRef(null); // Using useRef for recognition\n\n  const handleStop = () => {\n    setIsListening(false);\n    if (recognitionRef.current) {\n      recognitionRef.current.onresult = null; // Ensure no more results are processed\n      recognitionRef.current.stop();\n    }\n  };\n  const handleStart = () => {\n    if (window.SpeechRecognition || window.webkitSpeechRecognition) {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      if (!recognitionRef.current) {\n        recognitionRef.current = new SpeechRecognition();\n        recognitionRef.current.continuous = true;\n        recognitionRef.current.interimResults = true;\n      }\n      recognitionRef.current.onstart = () => setIsListening(true);\n      recognitionRef.current.onresult = event => {\n        let finalSpeech = '';\n        for (let i = 0; i < event.results.length; i++) {\n          if (event.results[i].isFinal) {\n            finalSpeech += event.results[i][0].transcript;\n          }\n        }\n        if (finalSpeech != '') {\n          console.log('finalspeech in voicetotext: ' + finalSpeech);\n          setUserSpeech(finalSpeech); // puts non-null user speech into the userSpeech variable accessible to gpt\n        }\n      };\n\n      recognitionRef.current.onerror = event => {\n        console.error(\"Error occurred in recognition:\", event.error);\n      };\n      recognitionRef.current.start();\n    } else {\n      alert(\"Your browser does not support the Web Speech API. Please try a different browser.\");\n    }\n  };\n  const handleGenerateAudio = async () => {\n    sendTranscriptToBackend(transcript);\n  };\n\n  // const sendTranscriptToBackend = async (text) => {\n  //     const backendUrl = 'http://127.0.0.1:5001/generate_audio';\n\n  //     try {\n  //         const response = await fetch(backendUrl, {\n  //             method: 'POST',\n  //             headers: {\n  //                 'Content-Type': 'application/json'\n  //             },\n  //             body: JSON.stringify({ text: text })\n  //         });\n\n  //         if (!response.ok) {\n  //             throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n  //         }\n\n  //         const responseData = await response.json();\n  //         setAudioFile(responseData.audio_file);\n\n  //     } catch (error) {\n  //         console.error('Error sending transcript to backend:', error);\n  //     }\n  // };\n\n  const sendTranscriptToBackend = async text => {\n    const apiUrl = \"https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM\";\n    const payload = {\n      \"text\": text,\n      \"model_id\": \"eleven_monolingual_v1\",\n      \"voice_settings\": {\n        \"stability\": 0,\n        \"similarity_boost\": 0,\n        \"style\": 0,\n        \"use_speaker_boost\": true\n      }\n    };\n    const headers = {\n      \"Content-Type\": \"application/json\",\n      \"xi-api-key\": \"ade7f1e13d6db219bf8d558f598c77b5\"\n    };\n    try {\n      const response = await fetch(apiUrl, {\n        method: 'POST',\n        headers: headers,\n        body: JSON.stringify(payload)\n      });\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n      }\n      const audioBlob = await response.blob();\n      const audioUrl = URL.createObjectURL(audioBlob);\n      setAudioFile(audioUrl);\n      console.log('Response:', response);\n      console.log('Audio Blob:', audioBlob);\n      console.log('Audio URL:', audioUrl);\n    } catch (error) {\n      console.error('Error sending transcript to Eleven Labs:', error);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      id: \"generate-audio-button\",\n      className: \"voice-to-text-button\",\n      onClick: isListening ? handleStop : handleStart,\n      children: isListening ? 'Stop Listening' : 'Start Listening'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 136,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"textarea\", {\n      id: \"text-area-placeholder\",\n      onChange: handleTranscriptChange,\n      value: transcript,\n      placeholder: \"Transcription will appear here...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 140,\n      columnNumber: 13\n    }, this), transcript && /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleGenerateAudio,\n      children: \"Generate Audio\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 148,\n      columnNumber: 17\n    }, this), audioFile && /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Your Generated Audio File:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 155,\n        columnNumber: 21\n      }, this), /*#__PURE__*/_jsxDEV(\"audio\", {\n        controls: true,\n        src: audioFile,\n        children: \"Your browser does not support the audio tag.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 156,\n        columnNumber: 21\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 154,\n      columnNumber: 17\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 135,\n    columnNumber: 9\n  }, this);\n};\n_s(VoiceToText, \"35Og3OqXtkj5HByzjBH/jabKZEk=\");\n_c = VoiceToText;\nexport default VoiceToText;\nvar _c;\n$RefreshReg$(_c, \"VoiceToText\");","map":{"version":3,"names":["React","useState","useRef","useEffect","jsxDEV","_jsxDEV","VoiceToText","transcript","setTranscript","setUserSpeech","_s","isListening","setIsListening","audioFile","setAudioFile","handleGenerateAudio","handleTranscriptChange","e","target","value","recognitionRef","handleStop","current","onresult","stop","handleStart","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","onstart","event","finalSpeech","i","results","length","isFinal","console","log","onerror","error","start","alert","sendTranscriptToBackend","text","apiUrl","payload","headers","response","fetch","method","body","JSON","stringify","ok","Error","status","statusText","audioBlob","blob","audioUrl","URL","createObjectURL","children","id","className","onClick","fileName","_jsxFileName","lineNumber","columnNumber","onChange","placeholder","controls","src","_c","$RefreshReg$"],"sources":["/Users/yashagrawal/Documents/Northwestern/Fall2023/CS338/InterviewPrep/src/components/VoiceToText.jsx"],"sourcesContent":["import React, { useState, useRef, useEffect } from 'react';\n\n// FOR NOW - TRANSCRIPT IS THE GPT RESPONSE INTO AUDIO, USERSPEECH IS THE SPEECH FROM USER GOING INTO GPT\n\nconst VoiceToText = ({ transcript, setTranscript, setUserSpeech }) => {\n    const [isListening, setIsListening] = useState(false);\n    const [audioFile, setAudioFile] = useState(null);\n\n    useEffect(() => {\n        if (transcript) {\n          // Automatically click the button when transcript is not empty\n          handleGenerateAudio();\n        }\n    }, [transcript]);\n\n    const handleTranscriptChange = (e) => {\n        setTranscript(e.target.value);\n    };\n\n    const recognitionRef = useRef(null);  // Using useRef for recognition\n\n    const handleStop = () => {\n        setIsListening(false);\n        if (recognitionRef.current) {\n            recognitionRef.current.onresult = null;  // Ensure no more results are processed\n            recognitionRef.current.stop();\n        }\n    };\n\n    const handleStart = () => {\n        if (window.SpeechRecognition || window.webkitSpeechRecognition) {\n            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n            if (!recognitionRef.current) {\n                recognitionRef.current = new SpeechRecognition();\n                recognitionRef.current.continuous = true;\n                recognitionRef.current.interimResults = true;\n            }\n\n            recognitionRef.current.onstart = () => setIsListening(true);\n\n            recognitionRef.current.onresult = (event) => {\n                let finalSpeech = '';\n                for (let i = 0; i < event.results.length; i++) {\n                    if (event.results[i].isFinal) {\n                        finalSpeech += event.results[i][0].transcript;\n                    }\n                }\n                if(finalSpeech != '') {\n                    console.log('finalspeech in voicetotext: ' + finalSpeech);\n                    setUserSpeech(finalSpeech); // puts non-null user speech into the userSpeech variable accessible to gpt\n                }\n            };\n\n            recognitionRef.current.onerror = (event) => {\n                console.error(\"Error occurred in recognition:\", event.error);\n            };\n\n            recognitionRef.current.start();\n        } else {\n            alert(\"Your browser does not support the Web Speech API. Please try a different browser.\");\n        }\n    };\n    \n\n    const handleGenerateAudio = async () => {\n        sendTranscriptToBackend(transcript);\n    };\n\n    // const sendTranscriptToBackend = async (text) => {\n    //     const backendUrl = 'http://127.0.0.1:5001/generate_audio';\n\n    //     try {\n    //         const response = await fetch(backendUrl, {\n    //             method: 'POST',\n    //             headers: {\n    //                 'Content-Type': 'application/json'\n    //             },\n    //             body: JSON.stringify({ text: text })\n    //         });\n\n    //         if (!response.ok) {\n    //             throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n    //         }\n\n    //         const responseData = await response.json();\n    //         setAudioFile(responseData.audio_file);\n\n    //     } catch (error) {\n    //         console.error('Error sending transcript to backend:', error);\n    //     }\n    // };\n    \n    const sendTranscriptToBackend = async (text) => {\n        const apiUrl = \"https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM\";\n        const payload = {\n            \"text\": text,\n            \"model_id\": \"eleven_monolingual_v1\",\n            \"voice_settings\": {\n                \"stability\": 0,\n                \"similarity_boost\": 0,\n                \"style\": 0,\n                \"use_speaker_boost\": true\n            }\n        };\n\n        const headers = {\n            \"Content-Type\": \"application/json\",\n            \"xi-api-key\": \"ade7f1e13d6db219bf8d558f598c77b5\"\n        };\n\n        try {\n            const response = await fetch(apiUrl, {\n                method: 'POST',\n                headers: headers,\n                body: JSON.stringify(payload)\n            });\n\n            if (!response.ok) {\n                throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);\n            }\n\n            const audioBlob = await response.blob();\n            const audioUrl = URL.createObjectURL(audioBlob);\n            setAudioFile(audioUrl);\n            console.log('Response:', response);\n            console.log('Audio Blob:', audioBlob);\n            console.log('Audio URL:', audioUrl);\n\n        } catch (error) {\n            console.error('Error sending transcript to Eleven Labs:', error);\n        }\n    };\n\n    return (\n        <div>\n            <button id=\"generate-audio-button\" className=\"voice-to-text-button\" \n                onClick={isListening ? handleStop : handleStart}>\n                {isListening ? 'Stop Listening' : 'Start Listening'}\n            </button>\n            <textarea \n                id='text-area-placeholder'\n                onChange={handleTranscriptChange} \n                value={transcript} \n                placeholder=\"Transcription will appear here...\"\n            ></textarea>\n            \n            {transcript && (\n                <button onClick={handleGenerateAudio}>\n                    Generate Audio\n                </button>\n            )}\n    \n            {audioFile && (\n                <div>\n                    <h3>Your Generated Audio File:</h3>\n                    <audio controls src={audioFile}>\n                        Your browser does not support the audio tag.\n                    </audio>\n                </div>\n            )}\n        </div>\n    );\n    \n};\n\nexport default VoiceToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;;AAE1D;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAEA,MAAMC,WAAW,GAAGA,CAAC;EAAEC,UAAU;EAAEC,aAAa;EAAEC;AAAc,CAAC,KAAK;EAAAC,EAAA;EAClE,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACY,SAAS,EAAEC,YAAY,CAAC,GAAGb,QAAQ,CAAC,IAAI,CAAC;EAEhDE,SAAS,CAAC,MAAM;IACZ,IAAII,UAAU,EAAE;MACd;MACAQ,mBAAmB,CAAC,CAAC;IACvB;EACJ,CAAC,EAAE,CAACR,UAAU,CAAC,CAAC;EAEhB,MAAMS,sBAAsB,GAAIC,CAAC,IAAK;IAClCT,aAAa,CAACS,CAAC,CAACC,MAAM,CAACC,KAAK,CAAC;EACjC,CAAC;EAED,MAAMC,cAAc,GAAGlB,MAAM,CAAC,IAAI,CAAC,CAAC,CAAE;;EAEtC,MAAMmB,UAAU,GAAGA,CAAA,KAAM;IACrBT,cAAc,CAAC,KAAK,CAAC;IACrB,IAAIQ,cAAc,CAACE,OAAO,EAAE;MACxBF,cAAc,CAACE,OAAO,CAACC,QAAQ,GAAG,IAAI,CAAC,CAAE;MACzCH,cAAc,CAACE,OAAO,CAACE,IAAI,CAAC,CAAC;IACjC;EACJ,CAAC;EAED,MAAMC,WAAW,GAAGA,CAAA,KAAM;IACtB,IAAIC,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB,EAAE;MAC5D,MAAMD,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;MACpF,IAAI,CAACR,cAAc,CAACE,OAAO,EAAE;QACzBF,cAAc,CAACE,OAAO,GAAG,IAAIK,iBAAiB,CAAC,CAAC;QAChDP,cAAc,CAACE,OAAO,CAACO,UAAU,GAAG,IAAI;QACxCT,cAAc,CAACE,OAAO,CAACQ,cAAc,GAAG,IAAI;MAChD;MAEAV,cAAc,CAACE,OAAO,CAACS,OAAO,GAAG,MAAMnB,cAAc,CAAC,IAAI,CAAC;MAE3DQ,cAAc,CAACE,OAAO,CAACC,QAAQ,GAAIS,KAAK,IAAK;QACzC,IAAIC,WAAW,GAAG,EAAE;QACpB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACG,OAAO,CAACC,MAAM,EAAEF,CAAC,EAAE,EAAE;UAC3C,IAAIF,KAAK,CAACG,OAAO,CAACD,CAAC,CAAC,CAACG,OAAO,EAAE;YAC1BJ,WAAW,IAAID,KAAK,CAACG,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC3B,UAAU;UACjD;QACJ;QACA,IAAG0B,WAAW,IAAI,EAAE,EAAE;UAClBK,OAAO,CAACC,GAAG,CAAC,8BAA8B,GAAGN,WAAW,CAAC;UACzDxB,aAAa,CAACwB,WAAW,CAAC,CAAC,CAAC;QAChC;MACJ,CAAC;;MAEDb,cAAc,CAACE,OAAO,CAACkB,OAAO,GAAIR,KAAK,IAAK;QACxCM,OAAO,CAACG,KAAK,CAAC,gCAAgC,EAAET,KAAK,CAACS,KAAK,CAAC;MAChE,CAAC;MAEDrB,cAAc,CAACE,OAAO,CAACoB,KAAK,CAAC,CAAC;IAClC,CAAC,MAAM;MACHC,KAAK,CAAC,mFAAmF,CAAC;IAC9F;EACJ,CAAC;EAGD,MAAM5B,mBAAmB,GAAG,MAAAA,CAAA,KAAY;IACpC6B,uBAAuB,CAACrC,UAAU,CAAC;EACvC,CAAC;;EAED;EACA;;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA;EACA;EACA;;EAEA;EACA;;EAEA;EACA;EACA;EACA;;EAEA,MAAMqC,uBAAuB,GAAG,MAAOC,IAAI,IAAK;IAC5C,MAAMC,MAAM,GAAG,kEAAkE;IACjF,MAAMC,OAAO,GAAG;MACZ,MAAM,EAAEF,IAAI;MACZ,UAAU,EAAE,uBAAuB;MACnC,gBAAgB,EAAE;QACd,WAAW,EAAE,CAAC;QACd,kBAAkB,EAAE,CAAC;QACrB,OAAO,EAAE,CAAC;QACV,mBAAmB,EAAE;MACzB;IACJ,CAAC;IAED,MAAMG,OAAO,GAAG;MACZ,cAAc,EAAE,kBAAkB;MAClC,YAAY,EAAE;IAClB,CAAC;IAED,IAAI;MACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAACJ,MAAM,EAAE;QACjCK,MAAM,EAAE,MAAM;QACdH,OAAO,EAAEA,OAAO;QAChBI,IAAI,EAAEC,IAAI,CAACC,SAAS,CAACP,OAAO;MAChC,CAAC,CAAC;MAEF,IAAI,CAACE,QAAQ,CAACM,EAAE,EAAE;QACd,MAAM,IAAIC,KAAK,CAAE,uBAAsBP,QAAQ,CAACQ,MAAO,IAAGR,QAAQ,CAACS,UAAW,EAAC,CAAC;MACpF;MAEA,MAAMC,SAAS,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;MACvC,MAAMC,QAAQ,GAAGC,GAAG,CAACC,eAAe,CAACJ,SAAS,CAAC;MAC/C7C,YAAY,CAAC+C,QAAQ,CAAC;MACtBvB,OAAO,CAACC,GAAG,CAAC,WAAW,EAAEU,QAAQ,CAAC;MAClCX,OAAO,CAACC,GAAG,CAAC,aAAa,EAAEoB,SAAS,CAAC;MACrCrB,OAAO,CAACC,GAAG,CAAC,YAAY,EAAEsB,QAAQ,CAAC;IAEvC,CAAC,CAAC,OAAOpB,KAAK,EAAE;MACZH,OAAO,CAACG,KAAK,CAAC,0CAA0C,EAAEA,KAAK,CAAC;IACpE;EACJ,CAAC;EAED,oBACIpC,OAAA;IAAA2D,QAAA,gBACI3D,OAAA;MAAQ4D,EAAE,EAAC,uBAAuB;MAACC,SAAS,EAAC,sBAAsB;MAC/DC,OAAO,EAAExD,WAAW,GAAGU,UAAU,GAAGI,WAAY;MAAAuC,QAAA,EAC/CrD,WAAW,GAAG,gBAAgB,GAAG;IAAiB;MAAAyD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/C,CAAC,eACTlE,OAAA;MACI4D,EAAE,EAAC,uBAAuB;MAC1BO,QAAQ,EAAExD,sBAAuB;MACjCG,KAAK,EAAEZ,UAAW;MAClBkE,WAAW,EAAC;IAAmC;MAAAL,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACxC,CAAC,EAEXhE,UAAU,iBACPF,OAAA;MAAQ8D,OAAO,EAAEpD,mBAAoB;MAAAiD,QAAA,EAAC;IAEtC;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CACX,EAEA1D,SAAS,iBACNR,OAAA;MAAA2D,QAAA,gBACI3D,OAAA;QAAA2D,QAAA,EAAI;MAA0B;QAAAI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACnClE,OAAA;QAAOqE,QAAQ;QAACC,GAAG,EAAE9D,SAAU;QAAAmD,QAAA,EAAC;MAEhC;QAAAI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAO,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACP,CACR;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACA,CAAC;AAGd,CAAC;AAAC7D,EAAA,CA/JIJ,WAAW;AAAAsE,EAAA,GAAXtE,WAAW;AAiKjB,eAAeA,WAAW;AAAC,IAAAsE,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}