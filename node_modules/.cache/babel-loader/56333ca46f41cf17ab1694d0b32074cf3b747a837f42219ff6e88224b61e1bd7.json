{"ast":null,"code":"var Token = require(\"./Token\");\nvar StringSource = require(\"./StringSource\");\nexports.RegexTokeniser = RegexTokeniser;\nfunction RegexTokeniser(rules) {\n  rules = rules.map(function (rule) {\n    return {\n      name: rule.name,\n      regex: new RegExp(rule.regex.source, \"g\")\n    };\n  });\n  function tokenise(input, description) {\n    var source = new StringSource(input, description);\n    var index = 0;\n    var tokens = [];\n    while (index < input.length) {\n      var result = readNextToken(input, index, source);\n      index = result.endIndex;\n      tokens.push(result.token);\n    }\n    tokens.push(endToken(input, source));\n    return tokens;\n  }\n  function readNextToken(string, startIndex, source) {\n    for (var i = 0; i < rules.length; i++) {\n      var regex = rules[i].regex;\n      regex.lastIndex = startIndex;\n      var result = regex.exec(string);\n      if (result) {\n        var endIndex = startIndex + result[0].length;\n        if (result.index === startIndex && endIndex > startIndex) {\n          var value = result[1];\n          var token = new Token(rules[i].name, value, source.range(startIndex, endIndex));\n          return {\n            token: token,\n            endIndex: endIndex\n          };\n        }\n      }\n    }\n    var endIndex = startIndex + 1;\n    var token = new Token(\"unrecognisedCharacter\", string.substring(startIndex, endIndex), source.range(startIndex, endIndex));\n    return {\n      token: token,\n      endIndex: endIndex\n    };\n  }\n  function endToken(input, source) {\n    return new Token(\"end\", null, source.range(input.length, input.length));\n  }\n  return {\n    tokenise: tokenise\n  };\n}","map":{"version":3,"names":["Token","require","StringSource","exports","RegexTokeniser","rules","map","rule","name","regex","RegExp","source","tokenise","input","description","index","tokens","length","result","readNextToken","endIndex","push","token","endToken","string","startIndex","i","lastIndex","exec","value","range","substring"],"sources":["/Users/yashagrawal/Documents/Northwestern/Fall2023/CS338/InterviewPrep/node_modules/lop/lib/regex-tokeniser.js"],"sourcesContent":["var Token = require(\"./Token\");\nvar StringSource = require(\"./StringSource\");\n\nexports.RegexTokeniser = RegexTokeniser;\n\nfunction RegexTokeniser(rules) {\n    rules = rules.map(function(rule) {\n        return {\n            name: rule.name,\n            regex: new RegExp(rule.regex.source, \"g\")\n        };\n    });\n    \n    function tokenise(input, description) {\n        var source = new StringSource(input, description);\n        var index = 0;\n        var tokens = [];\n    \n        while (index < input.length) {\n            var result = readNextToken(input, index, source);\n            index = result.endIndex;\n            tokens.push(result.token);\n        }\n        \n        tokens.push(endToken(input, source));\n        return tokens;\n    }\n\n    function readNextToken(string, startIndex, source) {\n        for (var i = 0; i < rules.length; i++) {\n            var regex = rules[i].regex;\n            regex.lastIndex = startIndex;\n            var result = regex.exec(string);\n            \n            if (result) {\n                var endIndex = startIndex + result[0].length;\n                if (result.index === startIndex && endIndex > startIndex) {\n                    var value = result[1];\n                    var token = new Token(\n                        rules[i].name,\n                        value,\n                        source.range(startIndex, endIndex)\n                    );\n                    return {token: token, endIndex: endIndex};\n                }\n            }\n        }\n        var endIndex = startIndex + 1;\n        var token = new Token(\n            \"unrecognisedCharacter\",\n            string.substring(startIndex, endIndex),\n            source.range(startIndex, endIndex)\n        );\n        return {token: token, endIndex: endIndex};\n    }\n    \n    function endToken(input, source) {\n        return new Token(\n            \"end\",\n            null,\n            source.range(input.length, input.length)\n        );\n    }\n    \n    return {\n        tokenise: tokenise\n    }\n}\n\n\n"],"mappings":"AAAA,IAAIA,KAAK,GAAGC,OAAO,CAAC,SAAS,CAAC;AAC9B,IAAIC,YAAY,GAAGD,OAAO,CAAC,gBAAgB,CAAC;AAE5CE,OAAO,CAACC,cAAc,GAAGA,cAAc;AAEvC,SAASA,cAAcA,CAACC,KAAK,EAAE;EAC3BA,KAAK,GAAGA,KAAK,CAACC,GAAG,CAAC,UAASC,IAAI,EAAE;IAC7B,OAAO;MACHC,IAAI,EAAED,IAAI,CAACC,IAAI;MACfC,KAAK,EAAE,IAAIC,MAAM,CAACH,IAAI,CAACE,KAAK,CAACE,MAAM,EAAE,GAAG;IAC5C,CAAC;EACL,CAAC,CAAC;EAEF,SAASC,QAAQA,CAACC,KAAK,EAAEC,WAAW,EAAE;IAClC,IAAIH,MAAM,GAAG,IAAIT,YAAY,CAACW,KAAK,EAAEC,WAAW,CAAC;IACjD,IAAIC,KAAK,GAAG,CAAC;IACb,IAAIC,MAAM,GAAG,EAAE;IAEf,OAAOD,KAAK,GAAGF,KAAK,CAACI,MAAM,EAAE;MACzB,IAAIC,MAAM,GAAGC,aAAa,CAACN,KAAK,EAAEE,KAAK,EAAEJ,MAAM,CAAC;MAChDI,KAAK,GAAGG,MAAM,CAACE,QAAQ;MACvBJ,MAAM,CAACK,IAAI,CAACH,MAAM,CAACI,KAAK,CAAC;IAC7B;IAEAN,MAAM,CAACK,IAAI,CAACE,QAAQ,CAACV,KAAK,EAAEF,MAAM,CAAC,CAAC;IACpC,OAAOK,MAAM;EACjB;EAEA,SAASG,aAAaA,CAACK,MAAM,EAAEC,UAAU,EAAEd,MAAM,EAAE;IAC/C,KAAK,IAAIe,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGrB,KAAK,CAACY,MAAM,EAAES,CAAC,EAAE,EAAE;MACnC,IAAIjB,KAAK,GAAGJ,KAAK,CAACqB,CAAC,CAAC,CAACjB,KAAK;MAC1BA,KAAK,CAACkB,SAAS,GAAGF,UAAU;MAC5B,IAAIP,MAAM,GAAGT,KAAK,CAACmB,IAAI,CAACJ,MAAM,CAAC;MAE/B,IAAIN,MAAM,EAAE;QACR,IAAIE,QAAQ,GAAGK,UAAU,GAAGP,MAAM,CAAC,CAAC,CAAC,CAACD,MAAM;QAC5C,IAAIC,MAAM,CAACH,KAAK,KAAKU,UAAU,IAAIL,QAAQ,GAAGK,UAAU,EAAE;UACtD,IAAII,KAAK,GAAGX,MAAM,CAAC,CAAC,CAAC;UACrB,IAAII,KAAK,GAAG,IAAItB,KAAK,CACjBK,KAAK,CAACqB,CAAC,CAAC,CAAClB,IAAI,EACbqB,KAAK,EACLlB,MAAM,CAACmB,KAAK,CAACL,UAAU,EAAEL,QAAQ,CACrC,CAAC;UACD,OAAO;YAACE,KAAK,EAAEA,KAAK;YAAEF,QAAQ,EAAEA;UAAQ,CAAC;QAC7C;MACJ;IACJ;IACA,IAAIA,QAAQ,GAAGK,UAAU,GAAG,CAAC;IAC7B,IAAIH,KAAK,GAAG,IAAItB,KAAK,CACjB,uBAAuB,EACvBwB,MAAM,CAACO,SAAS,CAACN,UAAU,EAAEL,QAAQ,CAAC,EACtCT,MAAM,CAACmB,KAAK,CAACL,UAAU,EAAEL,QAAQ,CACrC,CAAC;IACD,OAAO;MAACE,KAAK,EAAEA,KAAK;MAAEF,QAAQ,EAAEA;IAAQ,CAAC;EAC7C;EAEA,SAASG,QAAQA,CAACV,KAAK,EAAEF,MAAM,EAAE;IAC7B,OAAO,IAAIX,KAAK,CACZ,KAAK,EACL,IAAI,EACJW,MAAM,CAACmB,KAAK,CAACjB,KAAK,CAACI,MAAM,EAAEJ,KAAK,CAACI,MAAM,CAC3C,CAAC;EACL;EAEA,OAAO;IACHL,QAAQ,EAAEA;EACd,CAAC;AACL"},"metadata":{},"sourceType":"script","externalDependencies":[]}